{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Text**"
      ],
      "metadata": {
        "id": "_9nMEucRu49S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIMofcbwugRU"
      },
      "outputs": [],
      "source": [
        "sample_text = \"\"\"\n",
        "Markov chains are a type of statistical model that can be used to generate text.\n",
        "They work by predicting the next item in a sequence based on the previous item or items.\n",
        "This makes them useful for generating sequences that resemble natural language.\n",
        "You can use them for generating poems, dialogues, or even random text.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the Markov Chain**"
      ],
      "metadata": {
        "id": "LoCeaB0tu0k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_markov_chain(text, n=4):\n",
        "    words = text.split()\n",
        "    markov_chain = {}\n",
        "\n",
        "    for i in range(len(words) - n):\n",
        "        state = tuple(words[i:i+n])\n",
        "        next_word = words[i+n]\n",
        "        if state not in markov_chain:\n",
        "            markov_chain[state] = []\n",
        "        markov_chain[state].append(next_word)\n",
        "\n",
        "    return markov_chain\n"
      ],
      "metadata": {
        "id": "ewaQzr-muvXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate text using the Markov Chain**"
      ],
      "metadata": {
        "id": "CHInieY9vDMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_text(chain, length=50, seed=None):\n",
        "    if not seed:\n",
        "        seed = random.choice(list(chain.keys()))\n",
        "    output = list(seed)\n",
        "\n",
        "    for _ in range(length - len(seed)):\n",
        "        state = tuple(output[-len(seed):])\n",
        "        next_words = chain.get(state)\n",
        "        if not next_words:\n",
        "            break\n",
        "        next_word = random.choice(next_words)\n",
        "        output.append(next_word)\n",
        "\n",
        "    return ' '.join(output)\n"
      ],
      "metadata": {
        "id": "rCIBgbUMvGES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the chain and generate text**"
      ],
      "metadata": {
        "id": "5-fRUsXVvNb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = build_markov_chain(sample_text, n=2)  # You can try n=1 or n=3 too\n",
        "generated = generate_text(chain, length=30)\n",
        "print(\"Generated Text:\\n\", generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VqVkU7HvN_l",
        "outputId": "8ff4c99f-93fc-432c-9781-0ff9059e2d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " generating sequences that resemble natural language. You can use them for generating sequences that resemble natural language. You can use them for generating sequences that resemble natural language. You can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup and Imports**"
      ],
      "metadata": {
        "id": "uyt59PsUoAS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "id": "n0f1KQxxn_ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the MarkovChainTextGenerator class**"
      ],
      "metadata": {
        "id": "L3hIaZBHoG2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovChainTextGenerator:\n",
        "    def __init__(self):\n",
        "        self.model = defaultdict(list)\n",
        "\n",
        "    def train(self, text, n=2):\n",
        "        \"\"\"Train the model on the input text using n-grams (default is bigrams).\"\"\"\n",
        "        words = text.split()\n",
        "        for i in range(len(words) - n):\n",
        "            key = tuple(words[i:i+n-1])\n",
        "            next_word = words[i+n-1]\n",
        "            self.model[key].append(next_word)\n",
        "\n",
        "    def generate(self, length=50, seed=None):\n",
        "        \"\"\"Generate text of the given length using the trained model.\"\"\"\n",
        "        if not self.model:\n",
        "            return \"Model is not trained yet.\"\n",
        "\n",
        "        if seed is None:\n",
        "            seed = random.choice(list(self.model.keys()))\n",
        "        else:\n",
        "            seed = tuple(seed.split())\n",
        "\n",
        "        output = list(seed)\n",
        "        for _ in range(length):\n",
        "            state = tuple(output[-(len(seed)):])\n",
        "            next_words = self.model.get(state)\n",
        "            if not next_words:\n",
        "                break\n",
        "            next_word = random.choice(next_words)\n",
        "            output.append(next_word)\n",
        "        return ' '.join(output)\n"
      ],
      "metadata": {
        "id": "nx0qRmpnoHRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Provide sample training text**"
      ],
      "metadata": {
        "id": "0Vhsm3-EoPR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = \"\"\"\n",
        "In the neon-lit city of Comillas Negras, machines hummed under the pulse of ProDigy Infotech's servers.\n",
        "Text swirled across holographic displays, sentences weaving themselves out of code and rhythm.\n",
        "Markov chains spun tales not yet imagined, predicting each next word like a neon prophecy.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "dIKRpZdFoPpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model and generate text**"
      ],
      "metadata": {
        "id": "wuv3cMoaoYW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = MarkovChainTextGenerator()\n",
        "generator.train(text_data, n=3)  # n=2 for bigram model\n",
        "\n",
        "generated_text = generator.generate(length=40)\n",
        "print(\"ðŸ“„ Generated Text:\\n\")\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0of8F5AWoY2x",
        "outputId": "e4d0bb57-39ca-4657-e02a-3f5be3bd5119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“„ Generated Text:\n",
            "\n",
            "Comillas Negras, machines hummed under the pulse of ProDigy Infotech's servers. Text swirled across holographic displays, sentences weaving themselves out of code and rhythm. Markov chains spun tales not yet imagined, predicting each next word like a neon\n"
          ]
        }
      ]
    }
  ]
}